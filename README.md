# ğŸ¨ Fast Neural Style Transfer (PyTorch)

A **Fast Neural Style Transfer** implementation in **PyTorch** that generates stylized images in **real time** using a feed-forward neural network trained with **perceptual loss**.

This project is based on the idea introduced by *Johnson et al., 2016*, where a single neural network is trained per style to perform instant image stylization, unlike optimization-based Neural Style Transfer methods.

---

## âœ¨ Features

* ğŸš€ **Real-time style transfer** using a feed-forward CNN
* ğŸ§  **Perceptual loss** computed using a pretrained **VGG-16** network
* ğŸ” **Residual architecture** with Instance Normalization
* ğŸ–¼ï¸ Supports **training** and **inference** on custom datasets
* ğŸ“¦ **ONNX export** for deployment
* âš™ï¸ Clean, modular, and extensible PyTorch codebase

---

## ğŸ–¼ï¸ Results

Below are some example results generated by the model.

### Examples

```text
(Example 1.png)
```

```text
(Example 2.png)
```

```text
(App_ss_1.png)
```

> ğŸ“Œ Replace the filenames above with the actual image names present in your repository. GitHub will automatically render them.

---

## ğŸ—ï¸ Model Architecture

The model consists of:

* Initial convolution layers with **Reflection Padding**
* Downsampling using strided convolutions
* **5 Residual Blocks** for feature transformation
* Upsampling via nearest-neighbor interpolation + convolution
* **Instance Normalization** to stabilize and enhance stylization

The perceptual loss network uses a **pretrained VGG-16**, extracting features from:

* `relu1_2`
* `relu2_2`
* `relu3_3`
* `relu4_3`

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ neural_style.py        # Training & inference script
â”œâ”€â”€ transformer_net.py    # Feed-forward style transfer network
â”œâ”€â”€ vgg.py                # VGG-16 feature extractor for perceptual loss
â”œâ”€â”€ utils.py              # Image utils, Gram matrix, normalization
â”œâ”€â”€ images/               # Content, style, and output images
â””â”€â”€ README.md
```

---


## ğŸ§ª Loss Functions

* **Content Loss**: Mean Squared Error between content and generated image features
* **Style Loss**: Mean Squared Error between Gram matrices of style and generated image features

Both losses are computed in **feature space**, not pixel space.

---

## ğŸ“š References

* Johnson, J., Alahi, A., & Fei-Fei, L. *Perceptual Losses for Real-Time Style Transfer and Super-Resolution*, ECCV 2016
* Gatys, L. A., Ecker, A. S., & Bethge, M. *Image Style Transfer Using Convolutional Neural Networks*

---

## ğŸ™Œ Author

**Dhruv Garg**
Computer Vision & Deep Learning Enthusiast

---

## â­ Acknowledgements

* PyTorch Team
* torchvision pretrained models

If you find this project useful, consider giving it a â­ on GitHub!
